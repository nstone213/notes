Keras: the high level API for TensorFlow;
    Provides a highly productive interface for solving ML problems.
    Full access to the "scalability and cross-platform capabilities of TensorFlow.
    
Core data structures of Kera are <layers> and <models>.
    A layer is a simple input/output transformation, and a model is a directed, acyclic graph (DAG) of layers.

    Layers:
        import tensorflow as tf;
        tf.keras.layers.Layer -> class which is the fundamental abstraction in Keras. 
            A Layer encapsulates a state (weights) and some computation (Defined in the tf.keras.layers.Layer.call method);
            Weights created by layers can be trainable or non-trainable. Layers are recusively composable: If you assign a layer instance
                as an attribute of another layer, the outer layer will start tracking the weights created by the inner layer.
            You can also use layers to handle data preprocessing tasks like normalization and text vectorization. Preprocessing layers can be included
                directly into a model, either during or after training, which makes the model portable.
            
    Models:
        A model is an object that groups layers together and that can be trained on data.
        The simplest type of model is the <Sequential> model, which is a linear stack of layers. For more complex architectures, you can either use the 
            Keras functional API, which lets you build arbitrary graphs of layers, or use subclassing to write models from scratch.
        tf.keras.Model:
            tf.keras.Model.fit: trains the model for a fixed number of epochs.
            tf.keras.Model.predict: generates output predictions for the input samples.
            tf.keras.Model.evaluate: returns the loss and metrics values for the model; configured via the tf.keras.Model.compile method.

The Sequential Model
    Setup:
        import tensorflow as tf
        import keras
        from keras import layers
    
    When to use a Sequential Model:
        A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.
    
    A Sequential model is not appropriate when:
        Your model has multiple inputs or multiple outputs.
        Any of your layers has multiple inputs or multiple outputs.
        You need to do layer sharing.
        You want non-linear topology (i.e. a residual connection, a multi-branch model)

        .Dense:
            keras.layers.Dense(units, activation=None, ...);
                Units: the number of neurons or units in the layer. This determines the dimensionality of the output space.
                Activation: the activation function to apply to the output of the layer (i.e. relu, sigmoid, softmax). If no activation is specified,
                    it defaults to a linear activation (f(x) = x).
                    -> Activation functions are mathematical functions applied to the output of neurons in a neural network layer. They introduce
                        non-linearity into the model, allowing it to learn complex patterns and make accurate predictions.
                        ReLU (Rectified Linear Unit):
                            Returns 0 if the input is negative and returns the input itself if it's positive.
                            f(x) = max(0,x)
                            Helps avoid the vanishing gradient problem (A challenge that occurs when training deep neural networks using gradient-based learning methods) by maintaining a linear response for positive inputs.
                            Can lead to "dead neurons" (neuron that stop learning) if many neurons output 0.
                            Common in hidden layers of deep networks, especially convolutional networks (CNNs).
                Other parameters: You can specify other arguments like kernel initializer, bias initializer, regularization, etc., but units and activation
                    are the most important for most use cases.